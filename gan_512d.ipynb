{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9ab14793-90e7-4c0e-bc7f-58d111338f23",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "import GPUtil\n",
    "\n",
    "import src.shared.util as U\n",
    "import src.shared.augmentation as AUG\n",
    "#from src.decoder import Decoder\n",
    "from src.dataset.decode_dataset import DecodeDataset\n",
    "from src.shared.subdivide import Subdivide\n",
    "from decoder import Decoder\n",
    "\n",
    "torch.set_printoptions(sci_mode=False, precision=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5ea50693-6590-49d7-870e-2fa11aeaaeaf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "patch torch.Size([3, 256, 256])\n",
      "embedding torch.Size([3, 512])\n",
      "idx 0\n",
      "torch.Size([1, 3, 32, 32])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(torch.Size([1, 3, 512]),\n",
       " torch.Size([1, 3, 256, 256]),\n",
       " torch.Size([1, 3, 32, 32]))"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device('cuda')\n",
    "subdivide = Subdivide().to(device)\n",
    "\n",
    "patch_root = './data/fitted/512x512/'\n",
    "emb_file = ['./data/face_emb/', './data/face_emb_hq/',]\n",
    "n_embs = 3\n",
    "\n",
    "transform = lambda x: AUG.random_nth(x, 2)\n",
    "dataset = DecodeDataset(patch_root, emb_file, n_embs=n_embs, suffix='.pth', transform=transform)\n",
    "\n",
    "patch_mean = dataset.patch_data.mean(dim=0, keepdim=True)\n",
    "\n",
    "for k, v  in dataset[0].items():\n",
    "    print(k, v.shape if torch.is_tensor(v) else v)\n",
    "\n",
    "emb_sizes = (512,) * 3\n",
    "e_sz = 512\n",
    "\n",
    "mean = dataset.patch_data.mean(dim=0, keepdim=True)\n",
    "mean = mean.div(mean.abs().amax(dim=(1, 2, 3), keepdim=True))\n",
    "mean =  F.interpolate(mean, 32).cuda()\n",
    "print(mean.shape)\n",
    "\n",
    "emb, patch = [dataset[1][k][None].cuda() for  k in ('embedding', 'patch')]\n",
    "\n",
    "p_sz = 8\n",
    "e_sz = 512\n",
    "mid_sz = 64\n",
    "blocks = [\n",
    "    (1, 1, 2, 2,),\n",
    "    (3, 3, 4, 4,),\n",
    "    (5, 6, 7, 8,),\n",
    "    (10, 12, 14, 16,),\n",
    "]\n",
    "\n",
    "decoder = Decoder(16, 512, 192, blocks).cuda()\n",
    "\n",
    "decoder.load_state_dict(torch.load(f'./data/checkpoint/decoder512-{256}w.pth'))\n",
    "\n",
    "\n",
    "emb.shape, patch.shape, mean.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9a992fa2-45c5-4806-bc93-017e2beb726c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([1, 3, 512]),\n",
       " torch.Size([1, 3, 32, 32]),\n",
       " [torch.Size([1, 3, 32, 32]),\n",
       "  torch.Size([1, 3, 64, 64]),\n",
       "  torch.Size([1, 3, 128, 128]),\n",
       "  torch.Size([1, 3, 256, 256])])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emb.shape, mean.shape, [t.shape for t in decoder(emb, mean)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "09f79dc9-80bf-4a4d-96ba-4b71cb99270f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 1, 19, 19])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "PatchGAN Discriminator (https://github.com/junyanz/pytorch-CycleGAN-and-pix2pix/blob/master/models/networks.py#L538)\n",
    "\"\"\"\n",
    "\n",
    "import torch.nn as nn\n",
    "\n",
    "\n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(self, image_channels, num_filters_last=64, n_layers=3):\n",
    "        super(Discriminator, self).__init__()\n",
    "\n",
    "        layers = [nn.Conv2d(image_channels, num_filters_last, 7, 3), nn.LeakyReLU(0.2)]\n",
    "        num_filters_mult = 1\n",
    "\n",
    "        for i in range(1, n_layers + 1):\n",
    "            num_filters_mult_last = num_filters_mult\n",
    "            num_filters_mult = min(2 ** i, 8)\n",
    "            layers += [\n",
    "                nn.Conv2d(num_filters_last * num_filters_mult_last, num_filters_last * num_filters_mult, 4,\n",
    "                          2 if i < n_layers else 1, 1, bias=False),\n",
    "                nn.BatchNorm2d(num_filters_last * num_filters_mult),\n",
    "                nn.LeakyReLU(0.2, True)\n",
    "            ]\n",
    "\n",
    "        layers.append(nn.Conv2d(num_filters_last * num_filters_mult, 1, 4, 1, 1))\n",
    "        self.model = nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "\n",
    "discriminator =  Discriminator(3, 32).to(device)\n",
    "optimD = torch.optim.AdamW(discriminator.parameters(), lr=0.0002)\n",
    "discriminator(torch.randn(1, 3, 256,  256).to(device)).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b45be972-8e84-4e3e-a895-a81d8eb084d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "p_sz = 8\n",
    "e_sz = 512\n",
    "mid_sz = 64\n",
    "blocks = [    \n",
    "    #(5,  6,  7,  8,),\n",
    "    (9, 11, 13, 15, 16,),\n",
    "]\n",
    "\n",
    "generator =  Decoder(16, 512, 192, blocks).to(device)\n",
    "optimG =  torch.optim.AdamW(generator.parameters(), lr=0.0002)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5ef388ea-c84f-47e2-b873-1d134cfaeb76",
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = DataLoader(dataset, batch_size=32, shuffle=True, num_workers=0)\n",
    "# for g in optim.param_groups:\n",
    "#     #g['lr'] = 0.00005# 075\n",
    "#     print(g['lr'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "702baf0c-dfaa-4aa8-ad37-e7b6cccf94c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0 56.0 tensor(0.23056) tensor(0.22090) tensor(3.50133)\n",
      "0 50 69.0 tensor(0.20951) tensor(0.20948) tensor(2.91743)\n",
      "0 100 73.0 tensor(0.20966) tensor(0.21376) tensor(2.99928)\n",
      "0 150 77.0 tensor(0.20868) tensor(0.21102) tensor(2.91898)\n",
      "1 0 80.0 tensor(0.20326) tensor(0.21030) tensor(2.99533)\n",
      "1 50 84.0 tensor(0.20445) tensor(0.20516) tensor(2.86844)\n",
      "1 100 85.0 tensor(0.20901) tensor(0.21445) tensor(2.98051)\n",
      "1 150 86.0 tensor(0.20525) tensor(0.20537) tensor(2.85232)\n",
      "2 0 87.0 tensor(0.20835) tensor(0.21481) tensor(3.01564)\n",
      "2 50 90.0 tensor(0.21212) tensor(0.20971) tensor(2.80933)\n",
      "2 100 90.0 tensor(0.20590) tensor(0.21069) tensor(2.95996)\n",
      "2 150 91.0 tensor(0.20736) tensor(0.20964) tensor(2.95514)\n",
      "3 0 90.0 tensor(0.20561) tensor(0.20876) tensor(2.92113)\n",
      "3 50 91.0 tensor(0.21411) tensor(0.21871) tensor(2.96688)\n",
      "3 100 91.0 tensor(0.20871) tensor(0.21012) tensor(2.91594)\n",
      "3 150 91.0 tensor(0.23215) tensor(0.23464) tensor(2.86980)\n",
      "4 0 92.0 tensor(0.25701) tensor(0.25432) tensor(2.72472)\n",
      "4 50 91.0 tensor(0.21468) tensor(0.21610) tensor(2.96528)\n",
      "4 100 91.0 tensor(0.20745) tensor(0.21326) tensor(2.98836)\n",
      "4 150 91.0 tensor(0.20766) tensor(0.20960) tensor(2.93895)\n",
      "5 0 91.0 tensor(0.20849) tensor(0.21091) tensor(3.01553)\n",
      "5 50 91.0 tensor(0.24682) tensor(0.24822) tensor(2.76140)\n",
      "5 100 91.0 tensor(0.21290) tensor(0.21357) tensor(2.96249)\n",
      "5 150 91.0 tensor(0.22415) tensor(0.22631) tensor(2.94120)\n",
      "6 0 91.0 tensor(0.21838) tensor(0.21547) tensor(2.89083)\n",
      "6 50 91.0 tensor(0.21767) tensor(0.21848) tensor(2.92714)\n",
      "6 100 91.0 tensor(0.22204) tensor(0.22511) tensor(2.90875)\n",
      "6 150 91.0 tensor(0.22942) tensor(0.22387) tensor(2.83925)\n",
      "7 0 92.0 tensor(0.22563) tensor(0.22306) tensor(2.83906)\n",
      "7 50 91.0 tensor(0.20777) tensor(0.21222) tensor(2.97898)\n",
      "7 100 91.0 tensor(0.21063) tensor(0.22057) tensor(3.18769)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[19], line 34\u001b[0m\n\u001b[1;32m     32\u001b[0m error \u001b[38;5;241m=\u001b[39m error\n\u001b[1;32m     33\u001b[0m error\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[0;32m---> 34\u001b[0m errDF_lst\u001b[38;5;241m.\u001b[39mappend(\u001b[43merror\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m     36\u001b[0m optimD\u001b[38;5;241m.\u001b[39mstep()\n\u001b[1;32m     38\u001b[0m \u001b[38;5;66;03m##### Update G network: #####\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "epoch_no = 1_001\n",
    "\n",
    "keys = ('embedding', 'patch')\n",
    "\n",
    "lbl_real, lbl_fake = 1, 0\n",
    "loss_fn = F.binary_cross_entropy_with_logits\n",
    "errDR_lst, errDF_lst, errG_lst = [], [], []\n",
    "for epoch in range(epoch_no):\n",
    "    for step, batch in enumerate(iter(loader)):\n",
    "        patch_trg = batch['patch'].to(device)\n",
    "        emb = batch['embedding'].to(device)        \n",
    "        with torch.no_grad():\n",
    "            coarse = decoder(emb, mean)[-1]\n",
    "            \n",
    "        fake = generator(emb, coarse)[0]\n",
    "        \n",
    "        \n",
    "        ##### Update D network: #####\n",
    "        optimD.zero_grad()\n",
    "        \n",
    "        output = discriminator(patch_trg)\n",
    "        labels = torch.zeros_like(output) + lbl_real\n",
    "        labels = labels - torch.rand_like(labels).div(10)\n",
    "        error = loss_fn(output, labels)\n",
    "        error.backward()\n",
    "        errDR_lst.append(error.item())        \n",
    "        \n",
    "        output = discriminator(fake.detach())\n",
    "        labels = torch.zeros_like(output) + lbl_fake\n",
    "        labels = labels + torch.rand_like(labels).div(10)\n",
    "        error = loss_fn(output, labels)\n",
    "        error = error\n",
    "        error.backward()\n",
    "        errDF_lst.append(error.item())\n",
    "        \n",
    "        optimD.step()\n",
    "                            \n",
    "        ##### Update G network: #####\n",
    "        \n",
    "        output = discriminator(fake)  \n",
    "        labels = torch.zeros_like(output) + lbl_real\n",
    "        labels = labels - torch.rand_like(labels).div(10)\n",
    "        error = loss_fn(output, labels) + F.mse_loss(fake, patch_trg)       \n",
    "        errG_lst.append(error.item())\n",
    "        \n",
    "        optimG.zero_grad()\n",
    "        error.backward()\n",
    "        optimG.step()\n",
    "        \n",
    "        if step % 50 == 0:\n",
    "            temperature = GPUtil.getGPUs()[0].temperature\n",
    "            print(epoch, step, temperature,\n",
    "                  torch.tensor(errDR_lst).mean(),\n",
    "                  torch.tensor(errDF_lst).mean(),\n",
    "                  torch.tensor(errG_lst).mean(),)\n",
    "            errDR_lst, errDF_lst, errG_lst = [], [], []\n",
    "            if  temperature > 92:\n",
    "                while temperature > 70:\n",
    "                    print(f'GPU:{temperature}')\n",
    "                    time.sleep(10)\n",
    "                    temperature = GPUtil.getGPUs()[0].temperature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "96be5844-4b70-470b-8763-65dbe3fe06f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = DataLoader(dataset, batch_size=64, shuffle=True, num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f61fe502-31be-45eb-897c-8113008852b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, (pc, ps, pt) in enumerate(zip(coarse, fake, patch_trg)):\n",
    "    if i < 3:        \n",
    "        U.export_stl(pc, f'{i}crc')\n",
    "        U.export_stl(ps, f'{i}src')\n",
    "        U.export_stl(pt, f'{i}trg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "477b02c0-9ae5-4536-a076-8daa389d49a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimD = torch.optim.AdamW(discriminator.parameters(), lr=0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c3886ef1-7e74-4429-9297-9831e78e7af5",
   "metadata": {},
   "outputs": [],
   "source": [
    "patch_trg[:, :, 8:-8, 8:-8] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "186a33a7-890b-4560-9535-e939c512fcbb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 3, 16, 16])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "patch_trg[:, :, 8:-8, 8:-8] .shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3f6f9800-53c9-4126-932e-a076f9c30b35",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.08695, 0.01874, 0.09883, 0.02212, 0.06796, 0.06031, 0.08695, 0.03643,\n",
       "        0.02735, 0.01541])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.rand(10) / 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "492b646f-affc-4c61-8fa2-939f42a3c7bf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
