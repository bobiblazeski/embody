{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c2a373cb-b404-4a3a-b60c-6dcf69b050e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "import GPUtil\n",
    "\n",
    "import src.shared.util as U\n",
    "#from src.decoder import Decoder\n",
    "from src.dataset.decode_dataset import DecodeDataset\n",
    "from src.shared.subdivide import Subdivide\n",
    "\n",
    "torch.set_printoptions(sci_mode=False, precision=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f6d3248e-ef7e-4bb9-a7d8-980ac16d0872",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[torch.Size([7, 3, 32, 32]),\n",
       " torch.Size([7, 3, 64, 64]),\n",
       " torch.Size([7, 3, 128, 128]),\n",
       " torch.Size([7, 3, 256, 256])]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from einops import rearrange\n",
    "\n",
    "class Head(nn.Module):    \n",
    "\n",
    "    def __init__(self, p_sz, emb_sz, mid_sz, dropout=0.05):\n",
    "        super().__init__()\n",
    "        self.p_sz = p_sz\n",
    "        self.proj_emb = nn.Linear(emb_sz, mid_sz, bias=False)\n",
    "        self.proj_key = nn.Linear(3*p_sz**2, mid_sz, bias=False)\n",
    "        \n",
    "        self.net = nn.Sequential(            \n",
    "            nn.Dropout(dropout),\n",
    "            nn.ReLU(True),\n",
    "            nn.Linear(2*mid_sz, 3*p_sz**2, bias=False),\n",
    "        ) \n",
    "\n",
    "    def forward(self, x, emb):                \n",
    "        emb = self.proj_emb(emb)\n",
    "        u, v = x.size(-2) // self.p_sz, x.size(-1) // self.p_sz\n",
    "        y = rearrange(x, 'b c (u m) (v n) -> b (u v) (c m n)',\n",
    "                      m=self.p_sz, n=self.p_sz)        \n",
    "        y = self.proj_key(y)        \n",
    "        emb = emb.expand(-1, y.size(1), -1)\n",
    "        y = y.expand(emb.size(0), -1, -1)        \n",
    "        y = torch.cat([emb, y], dim=-1)        \n",
    "        y = self.net(y)\n",
    "        return rearrange(y, 'b (u v) (c m n) -> b c (u m) (v n)',\n",
    "                         c=3, u=u, v=v, m=self.p_sz, n=self.p_sz)\n",
    "        \n",
    "\n",
    "class MultiHead(nn.Module):\n",
    "    def __init__(self, p_sz, e_sz, mid_sz, sizes):\n",
    "        super().__init__()\n",
    "        self.p_sz = p_sz        \n",
    "        self.sizes = sizes\n",
    "        self.heads = nn.ModuleList([\n",
    "            Head(p_sz, e_sz, mid_sz) \n",
    "            for _ in sizes])\n",
    "\n",
    "    def forward(self, emb, mean):        \n",
    "        layers = [mean]        \n",
    "        for i, (head, sz) in enumerate(zip(self.heads, self.sizes)):                        \n",
    "            o = F.interpolate(mean, self.p_sz * sz, mode='bilinear')\n",
    "            y = head(o, emb)\n",
    "            layers.append(y)\n",
    "        return U.join(layers)\n",
    "\n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self, p_sz, e_sz, mid_sz, blocks):\n",
    "        super().__init__()\n",
    "        self.blocks = nn.ModuleList([\n",
    "            MultiHead(p_sz, e_sz, mid_sz, sizes)\n",
    "            for sizes  in blocks\n",
    "        ])\n",
    "    \n",
    "    def forward(self, emb, mean):\n",
    "        emb = emb.mean(dim=1, keepdim=True)        \n",
    "        res = []\n",
    "        for block in self.blocks:\n",
    "            mean = block(emb, mean)\n",
    "            res.append(mean)\n",
    "        return res\n",
    "        \n",
    "\n",
    "p_sz = 8\n",
    "e_sz = 512\n",
    "mid_sz = 64\n",
    "blocks = [\n",
    "    (1, 1, 2, 2,),\n",
    "    (3, 3, 4, 4,),\n",
    "    (5, 6, 7, 8,),\n",
    "    (10, 12, 14, 16,),\n",
    "]\n",
    "mean = torch.randn(1, 3, 256, 256).cuda()\n",
    "\n",
    "decoder = Decoder(16, 512, 192, blocks).cuda()\n",
    "\n",
    "decoder.load_state_dict(torch.load(f'./data/checkpoint/decoder512-{256}w.pth'))\n",
    "\n",
    "optim = torch.optim.AdamW(decoder.parameters(), lr=0.0002)\n",
    "optim.load_state_dict(torch.load(f'./data/checkpoint/optim/optim512-{256}w.pth'))\n",
    "\n",
    "[e.shape for e in  decoder(torch.randn(7, 3, 512).cuda(), mean)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "22146611-af2d-4156-a1db-92d1719e6722",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "patch torch.Size([3, 256, 256])\n",
      "embedding torch.Size([3, 512])\n",
      "idx 0\n",
      "torch.Size([1, 3, 512, 512])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(torch.Size([1, 3, 512]), torch.Size([1, 3, 256, 256]))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device('cuda')\n",
    "subdivide = Subdivide().to(device)\n",
    "\n",
    "patch_root = './data/fitted/512x512/'\n",
    "emb_file = ['./data/face_emb/', './data/face_emb_hq/',]\n",
    "n_embs = 3\n",
    "\n",
    "transform = lambda x: F.interpolate(x[None], 256)[0]\n",
    "dataset = DecodeDataset(patch_root, emb_file, n_embs=n_embs, suffix='.pth', transform=transform)\n",
    "\n",
    "patch_mean = dataset.patch_data.mean(dim=0, keepdim=True)\n",
    "\n",
    "for k, v  in dataset[0].items():\n",
    "    print(k, v.shape if torch.is_tensor(v) else v)\n",
    "\n",
    "emb_sizes = (512,) * 3\n",
    "e_sz = 512\n",
    "\n",
    "mean = dataset.patch_data.mean(dim=0, keepdim=True)\n",
    "print(mean.shape)\n",
    "\n",
    "emb, patch = [dataset[1][k][None].cuda() for  k in ('embedding', 'patch')]\n",
    "emb.shape, patch.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "07536202-61ae-4df8-865d-be736b46671a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5e-05\n"
     ]
    }
   ],
   "source": [
    "loader = DataLoader(dataset, batch_size=128, shuffle=True, num_workers=0)\n",
    "for g in optim.param_groups:\n",
    "    g['lr'] = 0.00005# 075\n",
    "    print(g['lr'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff20c0c8-a83e-42f1-9e05-9f6cf645aa43",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0000 0000 0.00008116 0.00005639 0.00005167 0.00005292 84.0\n",
      "0001 0000 0.00008058 0.00005618 0.00005156 0.00005274 89.0\n",
      "0002 0000 0.00007998 0.00005547 0.00005076 0.00005188 93.0\n",
      "GPU:93.0\n",
      "GPU:81.0\n"
     ]
    }
   ],
   "source": [
    "keys = ('embedding', 'patch')# 'dino1', 'dino2')\n",
    "#patch_mean =  patch_mean.to(device)\n",
    "from src.shared.sharpen import Sharpen\n",
    "sharpen = Sharpen(mask=('sharpen', '3x3_3'), padd=False).to(device)\n",
    "#offsets = [F.interpolate(mean, sz).cuda() for sz in  (8, 16, 32, 24, 40, 48, 56, 64)]\n",
    "#offsets = [F.interpolate(mean, sz).cuda() for sz in  [112, 256]] #[80, 112, 176, 256]]\n",
    "mean = dataset.patch_data.mean(dim=0, keepdim=True)\n",
    "mean = mean.div(mean.abs().amax(dim=(1, 2, 3), keepdim=True))\n",
    "mean =  F.interpolate(mean, 32).cuda()\n",
    "\n",
    "no_epochs = 1_001\n",
    "err_lst0, err_lst1, err_lst2, err_lst3  = [], [], [], []\n",
    "for epoch in range(no_epochs):\n",
    "    for step, batch in enumerate(loader):\n",
    "        #emb, patch_trg, mean, dino1, dino2 = (batch[k].cuda() for k in keys)\n",
    "        emb, patch_trg = (batch[k].cuda() for k in keys)\n",
    "        patch_trg = subdivide.smooth(patch_trg, interpolate=True)\n",
    "        patch_trg = patch_trg.div(patch_trg.abs().amax(dim=(1, 2, 3), keepdim=True))\n",
    "        \n",
    "        patch_src_lst = decoder(emb, mean) #+ patch_mean\n",
    "        errors =  [\n",
    "            F.mse_loss(F.interpolate(patch_src, patch_trg.size(-1), mode='bilinear'), patch_trg)            \n",
    "            for patch_src in patch_src_lst]\n",
    "        for err_lst, err in zip([err_lst0, err_lst1, err_lst2, err_lst3], errors):\n",
    "            err_lst.append(err.item())\n",
    "        #diff = (patch_src - patch_trg).abs()#.sum(dim=1, keepdim=True)\n",
    "        #mse_err = diff.mean() +  F.max_pool2d(diff, 16).mean()\n",
    "        #mse_err = F.mse_loss(patch_src, patch_trg)\n",
    "        \n",
    "        error = sum(errors) #+ 0.01 * F.l1_loss(patch_src, patch_trg)\n",
    "        \n",
    "        optim.zero_grad()\n",
    "        error.backward()\n",
    "        optim.step()\n",
    "        #err_lst.append(error.item())\n",
    "        if step % 100 == 0:\n",
    "            temperature = GPUtil.getGPUs()[0].temperature\n",
    "            if epoch % 1 == 0:\n",
    "                print(str(epoch).zfill(4), str(step).zfill(4), \n",
    "                      f'{torch.tensor(err_lst0).mean().item():.8f}',\n",
    "                      f'{torch.tensor(err_lst1).mean().item():.8f}',\n",
    "                      f'{torch.tensor(err_lst2).mean().item():.8f}',\n",
    "                      f'{torch.tensor(err_lst3).mean().item():.8f}',\n",
    "                      #f'{torch.tensor(sharpen_lst).mean().item():.8f}',\n",
    "                      temperature)\n",
    "                err_lst0, err_lst1, err_lst2, err_lst3  = [], [], [], []                             \n",
    "                \n",
    "            if  temperature > 92:\n",
    "                while temperature > 68:\n",
    "                    print(f'GPU:{temperature}')\n",
    "                    time.sleep(30)\n",
    "                    temperature = GPUtil.getGPUs()[0].temperature\n",
    "    if epoch % 3 ==0:      \n",
    "        size = patch_src_lst[-1].size(-1)\n",
    "        torch.save(decoder.state_dict(), f'./data/checkpoint/decoder512-{size}w.pth')\n",
    "        torch.save(optim.state_dict(), f'./data/checkpoint/optim/optim512-{size}w.pth')\n",
    "        for i, (pc, ps, pt) in enumerate(zip(patch_src_lst[0], patch_src_lst[-1], patch_trg)):\n",
    "            if i < 3:\n",
    "                U.export_stl(pc, f'{i}crc')\n",
    "                U.export_stl(ps, f'{i}src')\n",
    "                U.export_stl(pt, f'{i}trg')\n",
    "\n",
    "size = patch_src_lst[-1].size(-1)\n",
    "torch.save(decoder.state_dict(), f'./data/checkpoint/decoder512-{size}w.pth')\n",
    "torch.save(optim.state_dict(), f'./data/checkpoint/optim/optim512-{size}w.pth')\n",
    "# 0059 0000 0.00003770 0.00003576 0.00004650 0.00004472 93.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e766e7e7-5fba-42d4-b5a7-3c1733b93c1a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor(0.00013, device='cuda:0', grad_fn=<MseLossBackward0>),\n",
       " tensor(0.00010, device='cuda:0', grad_fn=<MseLossBackward0>),\n",
       " tensor(0.00010, device='cuda:0', grad_fn=<MseLossBackward0>),\n",
       " tensor(0.00011, device='cuda:0', grad_fn=<MseLossBackward0>)]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4c3d7808-8481-4971-861c-043d2ae8d187",
   "metadata": {},
   "outputs": [],
   "source": [
    "size = patch_trg.size(-1)\n",
    "torch.save(decoder.state_dict(), f'./data/checkpoint/decoder512-{size}w.pth')\n",
    "torch.save(optim.state_dict(), f'./data/checkpoint/optim/optim512-{size}w.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9b312f3e-1fd8-4183-b24f-a6765a493470",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, (pc, ps, pt) in enumerate(zip(patch_src_lst[0], patch_src_lst[-1], patch_trg)):\n",
    "    if i < 3:\n",
    "        U.export_stl(pc, f'{i}crc')\n",
    "        U.export_stl(ps, f'{i}src')\n",
    "        U.export_stl(pt, f'{i}trg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca658b17-7a41-46e7-916d-baffd3e309d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(str(epoch).zfill(4), str(step).zfill(4), \n",
    "                      f'{torch.tensor(err_lst).mean().item():.8f}', temperature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55934aca-4cd8-4220-a054-239541fc826a",
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = DataLoader(dataset, batch_size=8, shuffle=False, num_workers=0)\n",
    "decoded512_32 = torch.zeros(len(dataset), 3, 32, 32)\n",
    "orig_512_32 = torch.zeros(len(dataset), 3, 32, 32)\n",
    "device = torch.device('cuda')\n",
    "\n",
    "bsz = 8\n",
    "keys = ('embedding', 'patch')\n",
    "for i, batch in enumerate(loader):\n",
    "    emb, orig = (batch[k].to(device) for k in keys)    \n",
    "    with torch.no_grad():\n",
    "        coarse = decoder(emb)        \n",
    "    decoded512_32[i*bsz: (i+1) * bsz] = coarse\n",
    "    orig_512_32[i*bsz: (i+1) * bsz] = orig\n",
    "\n",
    "torch.save(decoded512_32, './data/decoded512_32j.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a06afc9b-ac8b-48e2-86be-4f69c30313e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in [100, 700, 2300]:\n",
    "    U.export_stl(orig_512_32[i], f'{i}org')\n",
    "    U.export_stl(decoded512_32[i], f'{i}src')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4111a55-e8c6-4972-b1db-a4960c4d6659",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.patch_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c276845-4e87-4942-9040-e8464412f1d2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
