{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c2a373cb-b404-4a3a-b60c-6dcf69b050e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "import GPUtil\n",
    "\n",
    "import src.shared.util as U\n",
    "#from src.decoder import Decoder\n",
    "from src.dataset.decode_dataset import DecodeDataset\n",
    "from src.shared.subdivide import Subdivide\n",
    "\n",
    "torch.set_printoptions(sci_mode=False, precision=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f6d3248e-ef7e-4bb9-a7d8-980ac16d0872",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[torch.Size([7, 3, 32, 32]),\n",
       " torch.Size([7, 3, 64, 64]),\n",
       " torch.Size([7, 3, 128, 128]),\n",
       " torch.Size([7, 3, 256, 256])]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from einops import rearrange\n",
    "\n",
    "class Head(nn.Module):    \n",
    "\n",
    "    def __init__(self, p_sz, emb_sz, mid_sz):\n",
    "        super().__init__()\n",
    "        self.p_sz = p_sz\n",
    "        self.proj_emb = nn.Linear(emb_sz, mid_sz, bias=False)\n",
    "        self.proj_key = nn.Linear(3*p_sz**2, mid_sz, bias=False)        \n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(2*mid_sz, 2*mid_sz, bias=False),            \n",
    "            nn.ReLU(True),\n",
    "            nn.Linear(2*mid_sz, 3*p_sz**2, bias=False),\n",
    "        ) \n",
    "\n",
    "    def forward(self, x, emb):        \n",
    "        #emb = self.proj_emb(emb[:, None])\n",
    "        emb = self.proj_emb(emb)\n",
    "        u, v = x.size(-2) // self.p_sz, x.size(-1) // self.p_sz\n",
    "        y = rearrange(x, 'b c (u m) (v n) -> b (u v) (c m n)',\n",
    "                      m=self.p_sz, n=self.p_sz)        \n",
    "        y = self.proj_key(y)        \n",
    "        emb = emb.expand(-1, y.size(1), -1)\n",
    "        y = y.expand(emb.size(0), -1, -1)        \n",
    "        y = torch.cat([emb, y], dim=-1)        \n",
    "        y = self.net(y)\n",
    "        return rearrange(y, 'b (u v) (c m n) -> b c (u m) (v n)',\n",
    "                         c=3, u=u, v=v, m=self.p_sz, n=self.p_sz)\n",
    "        \n",
    "\n",
    "class MultiHead(nn.Module):\n",
    "    def __init__(self, p_sz, e_sz, mid_sz, sizes):\n",
    "        super().__init__()\n",
    "        self.p_sz = p_sz\n",
    "        self.sizes = sizes\n",
    "        self.heads = nn.ModuleList([\n",
    "            Head(p_sz, e_sz, mid_sz) \n",
    "            for _ in sizes])\n",
    "\n",
    "    def forward(self, emb, mean):        \n",
    "        layers = [mean]\n",
    "        for i, (head, sz) in enumerate(zip(self.heads, self.sizes)):                        \n",
    "            o = F.interpolate(mean, self.p_sz * sz, mode='bilinear')\n",
    "            y = head(o, emb)\n",
    "            layers.append(y)\n",
    "        return U.join(layers)\n",
    "\n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self, p_sz, e_sz, mid_sz, blocks):\n",
    "        super().__init__()\n",
    "        self.blocks = nn.ModuleList([\n",
    "            MultiHead(p_sz, e_sz, mid_sz, sizes)\n",
    "            for sizes  in blocks\n",
    "        ])\n",
    "    \n",
    "    def forward(self, emb, mean):\n",
    "        emb = emb.mean(dim=1, keepdim=True)        \n",
    "        res = []\n",
    "        for block in self.blocks:\n",
    "            mean = block(emb, mean)\n",
    "            res.append(mean)\n",
    "        return res\n",
    "        \n",
    "\n",
    "p_sz = 8\n",
    "e_sz = 512\n",
    "mid_sz = 64\n",
    "blocks = [\n",
    "    (1, 1, 2, 2,),\n",
    "    (3, 3, 4, 4,),\n",
    "    (5, 6, 7, 8,),\n",
    "    (10, 12, 14, 16,),\n",
    "]\n",
    "mean = torch.randn(1, 3, 256, 256).cuda()\n",
    "\n",
    "decoder = Decoder(16, 512, 192, blocks).cuda()\n",
    "\n",
    "decoder.load_state_dict(torch.load(f'./data/checkpoint/decoder512-{256}v.pth'))\n",
    "\n",
    "optim = torch.optim.AdamW(decoder.parameters(), lr=0.0002)\n",
    "optim.load_state_dict(torch.load(f'./data/checkpoint/optim/optim512-{256}v.pth'))\n",
    "\n",
    "[e.shape for e in  decoder(torch.randn(7, 3, 512).cuda(), mean)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "22146611-af2d-4156-a1db-92d1719e6722",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "patch torch.Size([3, 256, 256])\n",
      "embedding torch.Size([3, 512])\n",
      "idx 0\n",
      "torch.Size([1, 3, 512, 512])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(torch.Size([1, 3, 512]), torch.Size([1, 3, 256, 256]))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device('cuda')\n",
    "subdivide = Subdivide().to(device)\n",
    "#subdivide.smooth(patch_src, interpolate=True).shape\n",
    "#patch_root = './data/fitted/64x64/'\n",
    "patch_root = './data/fitted/512x512/'\n",
    "emb_file = ['./data/face_emb/', './data/face_emb_hq/',]\n",
    "n_embs = 3\n",
    "#transform = lambda x: U.split(x[None], sizes=(16,))[0][0]\n",
    "\n",
    "transform = lambda x: F.interpolate(x[None], 256)[0]\n",
    "dataset = DecodeDataset(patch_root, emb_file, n_embs=n_embs, suffix='.pth', transform=transform)\n",
    "\n",
    "patch_mean = dataset.patch_data.mean(dim=0, keepdim=True)\n",
    "#patch_mean = patch_mean.div(patch_mean.abs().amax(dim=(1, 2, 3), keepdim=True))\n",
    "#dataset = DecodeDataset(patch_root, emb_file, n_embs=n_embs, transform=transform)\n",
    "\n",
    "for k, v  in dataset[0].items():\n",
    "    print(k, v.shape if torch.is_tensor(v) else v)\n",
    "\n",
    "emb_sizes = (512,) * 3\n",
    "e_sz = 512\n",
    "#decoder = Decoder(64, 256, 64, e_sz).to(device)\n",
    "\n",
    "#optim = torch.optim.AdamW(decoder.parameters(), lr=0.0002)\n",
    "\n",
    "\n",
    "#torch.save(patch_mean, './mean128.pt')\n",
    "mean = dataset.patch_data.mean(dim=0, keepdim=True)\n",
    "#patch_mean = patch_mean.div(patch_mean.abs().amax(dim=(1, 2, 3), keepdim=True))\n",
    "#torch.save(patch_mean, 'mean256.pt')#\n",
    "print(mean.shape)\n",
    "\n",
    "emb, patch = [dataset[1][k][None].cuda() for  k in ('embedding', 'patch')]\n",
    "emb.shape, patch.shape#, F.mse_loss(decoder(emb), patch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "07536202-61ae-4df8-865d-be736b46671a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0001\n"
     ]
    }
   ],
   "source": [
    "loader = DataLoader(dataset, batch_size=16, shuffle=True, num_workers=0)\n",
    "for g in optim.param_groups:\n",
    "    #g['lr'] = 0.00075# 075\n",
    "    print(g['lr'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ff20c0c8-a83e-42f1-9e05-9f6cf645aa43",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0000 0000 0.00005880 0.00004860 0.00004861 0.00005669 72.0\n",
      "0000 0100 0.00044868 0.00060002 0.00338828 0.00734876 82.0\n",
      "0000 0200 0.00053034 0.00112699 0.00194456 0.01270921 85.0\n",
      "0000 0300 0.00036057 0.00050466 0.00054381 0.00056111 85.0\n",
      "0001 0000 0.00023965 0.00025564 0.00025672 0.00028042 86.0\n",
      "0001 0100 0.00019688 0.00020155 0.00020542 0.00022304 86.0\n",
      "0001 0200 0.00015525 0.00015698 0.00016126 0.00017482 87.0\n",
      "0001 0300 0.00014462 0.00014374 0.00014876 0.00015991 88.0\n",
      "0002 0000 0.00013014 0.00012886 0.00013418 0.00014357 89.0\n",
      "0002 0100 0.00011856 0.00011589 0.00012087 0.00012894 88.0\n",
      "0002 0200 0.00010868 0.00010460 0.00010955 0.00011682 89.0\n",
      "0002 0300 0.00010181 0.00009730 0.00010215 0.00010892 90.0\n",
      "0003 0000 0.00009748 0.00009209 0.00009722 0.00010317 91.0\n",
      "0003 0100 0.00009199 0.00008553 0.00008999 0.00009551 91.0\n",
      "0003 0200 0.00008927 0.00008281 0.00008716 0.00009206 91.0\n",
      "0003 0300 0.00008636 0.00007942 0.00008342 0.00008821 91.0\n",
      "0004 0000 0.00008460 0.00007688 0.00008065 0.00008488 91.0\n",
      "0004 0100 0.00007963 0.00007193 0.00007559 0.00007962 92.0\n",
      "0004 0200 0.00007820 0.00006965 0.00007308 0.00007689 93.0\n",
      "GPU:93.0\n",
      "GPU:86.0\n",
      "GPU:81.0\n",
      "GPU:77.0\n",
      "GPU:74.0\n",
      "GPU:72.0\n",
      "GPU:71.0\n",
      "GPU:69.0\n",
      "0004 0300 0.00007617 0.00006747 0.00007080 0.00007448 80.0\n",
      "0005 0000 0.00007671 0.00006766 0.00007073 0.00007426 83.0\n",
      "0005 0100 0.00007219 0.00006306 0.00006597 0.00006916 85.0\n",
      "0005 0200 0.00007362 0.00006384 0.00006655 0.00006966 85.0\n",
      "0005 0300 0.00007100 0.00006082 0.00006342 0.00006658 86.0\n",
      "0006 0000 0.00006975 0.00005970 0.00006217 0.00006513 86.0\n",
      "0006 0100 0.00006831 0.00005736 0.00005970 0.00006257 88.0\n",
      "0006 0200 0.00006564 0.00005569 0.00005795 0.00006067 89.0\n",
      "0006 0300 0.00006670 0.00005629 0.00005854 0.00006105 88.0\n",
      "0007 0000 0.00006524 0.00005403 0.00005599 0.00005850 88.0\n",
      "0007 0100 0.00006590 0.00005484 0.00005682 0.00005923 90.0\n",
      "0007 0200 0.00006554 0.00005422 0.00005605 0.00005840 91.0\n",
      "0007 0300 0.00006089 0.00004954 0.00005124 0.00005345 92.0\n",
      "0008 0000 0.00006260 0.00005109 0.00005271 0.00005491 91.0\n",
      "0008 0100 0.00006185 0.00005009 0.00005170 0.00005383 92.0\n",
      "0008 0200 0.00006276 0.00005047 0.00005196 0.00005412 93.0\n",
      "GPU:93.0\n",
      "GPU:86.0\n",
      "GPU:81.0\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 51\u001b[0m\n\u001b[1;32m     49\u001b[0m             \u001b[38;5;28;01mwhile\u001b[39;00m temperature \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m68\u001b[39m:\n\u001b[1;32m     50\u001b[0m                 \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mGPU:\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtemperature\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m---> 51\u001b[0m                 \u001b[43mtime\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msleep\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m30\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     52\u001b[0m                 temperature \u001b[38;5;241m=\u001b[39m GPUtil\u001b[38;5;241m.\u001b[39mgetGPUs()[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mtemperature\n\u001b[1;32m     53\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m epoch \u001b[38;5;241m%\u001b[39m \u001b[38;5;241m3\u001b[39m \u001b[38;5;241m==\u001b[39m\u001b[38;5;241m0\u001b[39m:      \n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "keys = ('embedding', 'patch')# 'dino1', 'dino2')\n",
    "#patch_mean =  patch_mean.to(device)\n",
    "from src.shared.sharpen import Sharpen\n",
    "sharpen = Sharpen(mask=('sharpen', '3x3_3'), padd=False).to(device)\n",
    "#offsets = [F.interpolate(mean, sz).cuda() for sz in  (8, 16, 32, 24, 40, 48, 56, 64)]\n",
    "#offsets = [F.interpolate(mean, sz).cuda() for sz in  [112, 256]] #[80, 112, 176, 256]]\n",
    "mean = dataset.patch_data.mean(dim=0, keepdim=True)\n",
    "mean = mean.div(mean.abs().amax(dim=(1, 2, 3), keepdim=True))\n",
    "mean =  F.interpolate(mean, 32).cuda()\n",
    "\n",
    "no_epochs = 1_001\n",
    "err_lst0, err_lst1, err_lst2, err_lst3  = [], [], [], []\n",
    "for epoch in range(no_epochs):\n",
    "    for step, batch in enumerate(loader):\n",
    "        #emb, patch_trg, mean, dino1, dino2 = (batch[k].cuda() for k in keys)\n",
    "        emb, patch_trg = (batch[k].cuda() for k in keys)\n",
    "        patch_trg = subdivide.smooth(patch_trg, interpolate=True)\n",
    "        patch_trg = patch_trg.div(patch_trg.abs().amax(dim=(1, 2, 3), keepdim=True))\n",
    "        \n",
    "        patch_src_lst = decoder(emb, mean) #+ patch_mean\n",
    "        errors =  [\n",
    "            F.mse_loss(F.interpolate(patch_src, patch_trg.size(-1), mode='bilinear'), patch_trg)            \n",
    "            for patch_src in patch_src_lst]\n",
    "        for err_lst, err in zip([err_lst0, err_lst1, err_lst2, err_lst3], errors):\n",
    "            err_lst.append(err.item())\n",
    "        #diff = (patch_src - patch_trg).abs()#.sum(dim=1, keepdim=True)\n",
    "        #mse_err = diff.mean() +  F.max_pool2d(diff, 16).mean()\n",
    "        #mse_err = F.mse_loss(patch_src, patch_trg)\n",
    "        \n",
    "        error = sum(errors) #+ 0.01 * F.l1_loss(patch_src, patch_trg)\n",
    "        \n",
    "        optim.zero_grad()\n",
    "        error.backward()\n",
    "        optim.step()\n",
    "        #err_lst.append(error.item())\n",
    "        if step % 100 == 0:\n",
    "            temperature = GPUtil.getGPUs()[0].temperature\n",
    "            if epoch % 1 == 0:\n",
    "                print(str(epoch).zfill(4), str(step).zfill(4), \n",
    "                      f'{torch.tensor(err_lst0).mean().item():.8f}',\n",
    "                      f'{torch.tensor(err_lst1).mean().item():.8f}',\n",
    "                      f'{torch.tensor(err_lst2).mean().item():.8f}',\n",
    "                      f'{torch.tensor(err_lst3).mean().item():.8f}',\n",
    "                      #f'{torch.tensor(sharpen_lst).mean().item():.8f}',\n",
    "                      temperature)\n",
    "                err_lst0, err_lst1, err_lst2, err_lst3  = [], [], [], []                             \n",
    "                \n",
    "            if  temperature > 92:\n",
    "                while temperature > 68:\n",
    "                    print(f'GPU:{temperature}')\n",
    "                    time.sleep(30)\n",
    "                    temperature = GPUtil.getGPUs()[0].temperature\n",
    "    if epoch % 3 ==0:      \n",
    "        size = patch_src_lst[-1].size(-1)\n",
    "        torch.save(decoder.state_dict(), f'./data/checkpoint/decoder512-{size}v.pth')\n",
    "        torch.save(optim.state_dict(), f'./data/checkpoint/optim/optim512-{size}v.pth')\n",
    "        for i, (pc, ps, pt) in enumerate(zip(patch_src_lst[0], patch_src_lst[-1], patch_trg)):\n",
    "            if i < 3:\n",
    "                U.export_stl(pc, f'{i}crc')\n",
    "                U.export_stl(ps, f'{i}src')\n",
    "                U.export_stl(pt, f'{i}trg')\n",
    "\n",
    "size = patch_src_lst[-1].size(-1)\n",
    "torch.save(decoder.state_dict(), f'./data/checkpoint/decoder512-{size}v.pth')\n",
    "torch.save(optim.state_dict(), f'./data/checkpoint/optim/optim512-{size}v.pth')\n",
    "# 0059 0000 0.00003770 0.00003576 0.00004650 0.00004472 93.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e766e7e7-5fba-42d4-b5a7-3c1733b93c1a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor(    0.00006, device='cuda:0', grad_fn=<MseLossBackward0>),\n",
       " tensor(    0.00004, device='cuda:0', grad_fn=<MseLossBackward0>),\n",
       " tensor(    0.00005, device='cuda:0', grad_fn=<MseLossBackward0>),\n",
       " tensor(    0.00005, device='cuda:0', grad_fn=<MseLossBackward0>)]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4c3d7808-8481-4971-861c-043d2ae8d187",
   "metadata": {},
   "outputs": [],
   "source": [
    "size = patch_trg.size(-1)\n",
    "torch.save(decoder.state_dict(), f'./data/checkpoint/decoder512-{size}v.pth')\n",
    "torch.save(optim.state_dict(), f'./data/checkpoint/optim/optim512-{size}v.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c80bfd2d-9612-437e-8e9f-fc45df03ad92",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(decoder.state_dict(), f'decoder512-{patch_trg.size(-1)}_{8}.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9b312f3e-1fd8-4183-b24f-a6765a493470",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, (pc, ps, pt) in enumerate(zip(patch_src_lst[0], patch_src_lst[-1], patch_trg)):\n",
    "    if i < 3:\n",
    "        U.export_stl(pc, f'{i}crc')\n",
    "        U.export_stl(ps, f'{i}src')\n",
    "        U.export_stl(pt, f'{i}trg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca658b17-7a41-46e7-916d-baffd3e309d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(str(epoch).zfill(4), str(step).zfill(4), \n",
    "                      f'{torch.tensor(err_lst).mean().item():.8f}', temperature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55934aca-4cd8-4220-a054-239541fc826a",
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = DataLoader(dataset, batch_size=8, shuffle=False, num_workers=0)\n",
    "decoded512_32 = torch.zeros(len(dataset), 3, 32, 32)\n",
    "orig_512_32 = torch.zeros(len(dataset), 3, 32, 32)\n",
    "device = torch.device('cuda')\n",
    "\n",
    "bsz = 8\n",
    "keys = ('embedding', 'patch')\n",
    "for i, batch in enumerate(loader):\n",
    "    emb, orig = (batch[k].to(device) for k in keys)    \n",
    "    with torch.no_grad():\n",
    "        coarse = decoder(emb)        \n",
    "    decoded512_32[i*bsz: (i+1) * bsz] = coarse\n",
    "    orig_512_32[i*bsz: (i+1) * bsz] = orig\n",
    "\n",
    "torch.save(decoded512_32, './data/decoded512_32j.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a06afc9b-ac8b-48e2-86be-4f69c30313e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in [100, 700, 2300]:\n",
    "    U.export_stl(orig_512_32[i], f'{i}org')\n",
    "    U.export_stl(decoded512_32[i], f'{i}src')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4111a55-e8c6-4972-b1db-a4960c4d6659",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.patch_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c276845-4e87-4942-9040-e8464412f1d2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
