{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9ab14793-90e7-4c0e-bc7f-58d111338f23",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "import GPUtil\n",
    "\n",
    "import src.shared.util as U\n",
    "import src.shared.augmentation as AUG\n",
    "#from src.decoder import Decoder\n",
    "from src.dataset.decode_dataset import DecodeDataset\n",
    "from src.shared.subdivide import Subdivide\n",
    "from decoder import Decoder\n",
    "\n",
    "torch.set_printoptions(sci_mode=False, precision=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5ea50693-6590-49d7-870e-2fa11aeaaeaf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "patch torch.Size([3, 256, 256])\n",
      "embedding torch.Size([3, 512])\n",
      "idx 0\n",
      "torch.Size([1, 3, 32, 32])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(torch.Size([1, 3, 512]),\n",
       " torch.Size([1, 3, 256, 256]),\n",
       " torch.Size([1, 3, 32, 32]))"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device('cuda')\n",
    "subdivide = Subdivide().to(device)\n",
    "\n",
    "patch_root = './data/fitted/512x512/'\n",
    "emb_file = ['./data/face_emb/', './data/face_emb_hq/',]\n",
    "n_embs = 3\n",
    "\n",
    "transform = lambda x: AUG.random_nth(x, 2)\n",
    "dataset = DecodeDataset(patch_root, emb_file, n_embs=n_embs, suffix='.pth', transform=transform)\n",
    "\n",
    "patch_mean = dataset.patch_data.mean(dim=0, keepdim=True)\n",
    "\n",
    "for k, v  in dataset[0].items():\n",
    "    print(k, v.shape if torch.is_tensor(v) else v)\n",
    "\n",
    "emb_sizes = (512,) * 3\n",
    "e_sz = 512\n",
    "\n",
    "mean = dataset.patch_data.mean(dim=0, keepdim=True)\n",
    "mean = mean.div(mean.abs().amax(dim=(1, 2, 3), keepdim=True))\n",
    "mean =  F.interpolate(mean, 32).cuda()\n",
    "print(mean.shape)\n",
    "\n",
    "emb, patch = [dataset[1][k][None].cuda() for  k in ('embedding', 'patch')]\n",
    "\n",
    "p_sz = 8\n",
    "e_sz = 512\n",
    "mid_sz = 64\n",
    "blocks = [\n",
    "    (1, 1, 2, 2,),\n",
    "    (3, 3, 4, 4,),\n",
    "    (5, 6, 7, 8,),\n",
    "    (10, 12, 14, 16,),\n",
    "]\n",
    "\n",
    "decoder = Decoder(16, 512, 192, blocks).cuda()\n",
    "\n",
    "decoder.load_state_dict(torch.load(f'./data/checkpoint/decoder512-{256}w.pth'))\n",
    "\n",
    "\n",
    "emb.shape, patch.shape, mean.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9a992fa2-45c5-4806-bc93-017e2beb726c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([1, 3, 512]),\n",
       " torch.Size([1, 3, 32, 32]),\n",
       " [torch.Size([1, 3, 32, 32]),\n",
       "  torch.Size([1, 3, 64, 64]),\n",
       "  torch.Size([1, 3, 128, 128]),\n",
       "  torch.Size([1, 3, 256, 256])])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emb.shape, mean.shape, [t.shape for t in decoder(emb, mean)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "09f79dc9-80bf-4a4d-96ba-4b71cb99270f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 1, 19, 19])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "PatchGAN Discriminator (https://github.com/junyanz/pytorch-CycleGAN-and-pix2pix/blob/master/models/networks.py#L538)\n",
    "\"\"\"\n",
    "\n",
    "import torch.nn as nn\n",
    "\n",
    "\n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(self, image_channels, num_filters_last=64, n_layers=3):\n",
    "        super(Discriminator, self).__init__()\n",
    "\n",
    "        layers = [nn.Conv2d(image_channels, num_filters_last, 7, 3), nn.LeakyReLU(0.2)]\n",
    "        num_filters_mult = 1\n",
    "\n",
    "        for i in range(1, n_layers + 1):\n",
    "            num_filters_mult_last = num_filters_mult\n",
    "            num_filters_mult = min(2 ** i, 8)\n",
    "            layers += [\n",
    "                nn.Conv2d(num_filters_last * num_filters_mult_last, num_filters_last * num_filters_mult, 4,\n",
    "                          2 if i < n_layers else 1, 1, bias=False),\n",
    "                nn.BatchNorm2d(num_filters_last * num_filters_mult),\n",
    "                nn.LeakyReLU(0.2, True)\n",
    "            ]\n",
    "\n",
    "        layers.append(nn.Conv2d(num_filters_last * num_filters_mult, 1, 4, 1, 1))\n",
    "        self.model = nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "\n",
    "discriminator =  Discriminator(3, 32).to(device)\n",
    "optimD = torch.optim.AdamW(discriminator.parameters(), lr=0.0002)\n",
    "discriminator(torch.randn(1, 3, 256,  256).to(device)).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b45be972-8e84-4e3e-a895-a81d8eb084d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "p_sz = 8\n",
    "e_sz = 512\n",
    "mid_sz = 64\n",
    "blocks = [    \n",
    "    #(5,  6,  7,  8,),\n",
    "    (9, 11, 13, 15, 16,),\n",
    "]\n",
    "\n",
    "generator =  Decoder(16, 512, 192, blocks).to(device)\n",
    "optimG =  torch.optim.AdamW(generator.parameters(), lr=0.0002)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5ef388ea-c84f-47e2-b873-1d134cfaeb76",
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = DataLoader(dataset, batch_size=32, shuffle=True, num_workers=0)\n",
    "# for g in optim.param_groups:\n",
    "#     #g['lr'] = 0.00005# 075\n",
    "#     print(g['lr'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "702baf0c-dfaa-4aa8-ad37-e7b6cccf94c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0 63.0 tensor(0.70843) tensor(0.75907)\n",
      "0 50 73.0 tensor(0.52876) tensor(0.55006)\n",
      "0 100 76.0 tensor(0.51805) tensor(0.48044)\n",
      "0 150 79.0 tensor(0.50872) tensor(0.41785)\n",
      "1 0 81.0 tensor(0.51169) tensor(0.35214)\n",
      "1 50 83.0 tensor(0.50401) tensor(0.30887)\n",
      "1 100 86.0 tensor(0.50247) tensor(0.27693)\n",
      "1 150 86.0 tensor(0.50488) tensor(0.24632)\n",
      "2 0 87.0 tensor(0.50386) tensor(0.23003)\n",
      "2 50 89.0 tensor(0.49239) tensor(0.22668)\n",
      "2 100 91.0 tensor(0.50873) tensor(0.23133)\n",
      "2 150 91.0 tensor(0.50663) tensor(0.21868)\n",
      "3 0 91.0 tensor(0.50801) tensor(0.20390)\n",
      "3 50 92.0 tensor(0.50484) tensor(0.19461)\n",
      "3 100 91.0 tensor(0.50811) tensor(0.18791)\n",
      "3 150 91.0 tensor(0.49591) tensor(0.18533)\n",
      "4 0 91.0 tensor(0.50133) tensor(0.17895)\n",
      "4 50 91.0 tensor(0.50392) tensor(0.17696)\n",
      "4 100 91.0 tensor(0.50672) tensor(0.17745)\n",
      "4 150 91.0 tensor(0.49844) tensor(0.18332)\n",
      "5 0 91.0 tensor(0.50484) tensor(0.19530)\n",
      "5 50 91.0 tensor(0.50488) tensor(0.20274)\n",
      "5 100 91.0 tensor(0.50932) tensor(0.23851)\n",
      "5 150 91.0 tensor(0.50745) tensor(0.23894)\n",
      "6 0 90.0 tensor(0.49808) tensor(0.22875)\n",
      "6 50 91.0 tensor(0.50636) tensor(0.23476)\n",
      "6 100 91.0 tensor(0.50828) tensor(0.22062)\n",
      "6 150 91.0 tensor(0.50300) tensor(0.20291)\n",
      "7 0 91.0 tensor(0.49709) tensor(0.18938)\n",
      "7 50 90.0 tensor(0.50922) tensor(0.17485)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[16], line 9\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(epoch_no):\n\u001b[1;32m      8\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m step, batch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(\u001b[38;5;28miter\u001b[39m(loader)):\n\u001b[0;32m----> 9\u001b[0m         patch_trg \u001b[38;5;241m=\u001b[39m \u001b[43mbatch\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mpatch\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     10\u001b[0m         emb \u001b[38;5;241m=\u001b[39m batch[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124membedding\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mto(device)        \n\u001b[1;32m     11\u001b[0m         \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "epoch_no = 1_001\n",
    "\n",
    "keys = ('embedding', 'patch')\n",
    "\n",
    "loss_fn = F.binary_cross_entropy_with_logits\n",
    "errD_lst, errG_lst = [], []\n",
    "for epoch in range(epoch_no):\n",
    "    for step, batch in enumerate(iter(loader)):\n",
    "        patch_trg = batch['patch'].to(device)\n",
    "        emb = batch['embedding'].to(device)        \n",
    "        with torch.no_grad():\n",
    "            coarse = decoder(emb, mean)[-1]\n",
    "            \n",
    "        fake = generator(emb, coarse)[0]\n",
    "        \n",
    "        ratios  = torch.rand(fake.size(0), 1, 1, 1, device=device)\n",
    "        blend = ratios * patch_trg +  (1-ratios) * fake.detach()\n",
    "        ##### Update D network: #####\n",
    "        output = discriminator(blend)\n",
    "        labels = ratios.expand(-1, -1, output.size(-2), output.size(-2))\n",
    "        error = loss_fn(output, labels)\n",
    "        errD_lst.append(error.item())\n",
    "        \n",
    "        optimD.zero_grad()\n",
    "        error.backward()        \n",
    "        optimD.step()\n",
    "                                \n",
    "        ##### Update G network: #####\n",
    "        \n",
    "        \n",
    "        output = discriminator(fake)        \n",
    "        error = loss_fn(output, torch.zeros_like(output))        \n",
    "        errG_lst.append(error.item())\n",
    "        \n",
    "        optimG.zero_grad()\n",
    "        error.backward()\n",
    "        optimG.step()\n",
    "        \n",
    "        if step % 50 == 0:\n",
    "            temperature = GPUtil.getGPUs()[0].temperature\n",
    "            print(epoch, step, temperature,\n",
    "                  torch.tensor(errD_lst).mean(), \n",
    "                  torch.tensor(errG_lst).mean(),)\n",
    "            errD_lst, errG_lst = [], []\n",
    "            if  temperature > 92:\n",
    "                while temperature > 70:\n",
    "                    print(f'GPU:{temperature}')\n",
    "                    time.sleep(10)\n",
    "                    temperature = GPUtil.getGPUs()[0].temperature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "96be5844-4b70-470b-8763-65dbe3fe06f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = DataLoader(dataset, batch_size=64, shuffle=True, num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f61fe502-31be-45eb-897c-8113008852b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, (pc, ps, pt) in enumerate(zip(coarse, fake, patch_trg)):\n",
    "    if i < 3:        \n",
    "        U.export_stl(pc, f'{i}crc')\n",
    "        U.export_stl(ps, f'{i}src')\n",
    "        U.export_stl(pt, f'{i}trg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "477b02c0-9ae5-4536-a076-8daa389d49a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimD = torch.optim.AdamW(discriminator.parameters(), lr=0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c3886ef1-7e74-4429-9297-9831e78e7af5",
   "metadata": {},
   "outputs": [],
   "source": [
    "patch_trg[:, :, 8:-8, 8:-8] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "186a33a7-890b-4560-9535-e939c512fcbb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 3, 16, 16])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "patch_trg[:, :, 8:-8, 8:-8] .shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f6f9800-53c9-4126-932e-a076f9c30b35",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
